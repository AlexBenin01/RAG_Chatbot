# ğŸ¤– RAG Chatbot â€” Intelligent PDF Analysis

**RAG Chatbot** Ã¨ una web application per lâ€™analisi intelligente di documenti PDF basata su architettura **Retrieval-Augmented Generation (RAG)**.  
Consente di caricare un PDF e interrogare il contenuto tramite unâ€™interfaccia chat moderna, accessibile e responsive.

> Progetto focalizzato su **AI applicata**, **LLM orchestration**, **UX accessibile (WCAG 2.1)** e **best practice software engineering**.

---

## âœ¨ Features principali

- ğŸ“„ **Upload PDF** (max 20MB)
- ğŸ” **Indicizzazione semantica** con embedding vettoriali
- ğŸ¤– **Chat intelligente** basata su LLM (Ollama o OpenAI)
- âš¡ **Risposte contestuali** tramite RetrievalQA
- ğŸ¨ **UI moderna e accessibile** (WCAG 2.1 AAA-oriented)
- ğŸŒ™ **Dark / Light mode automatico**
- ğŸ§  **Caching dei documenti** per performance migliori
- ğŸ§¹ **Pulizia automatica dellâ€™output LLM** (no reasoning leaks)

---

## ğŸ§  Architettura

PDF
â””â”€â–º Loader (PyPDF)
â””â”€â–º Text Splitter
â””â”€â–º Embedding Model
â””â”€â–º Vector Store (Chroma)
â””â”€â–º Retriever
â””â”€â–º LLM
â””â”€â–º Chat UI (Gradio)

### Pattern utilizzati
- **RAG (Retrieval-Augmented Generation)**
- **Separation of Concerns**
- **Streaming response**
- **LLM-agnostic backend**
- **Design tokens + deterministic CSS**

---

## ğŸ› ï¸ Tech Stack

### Frontend
- **Gradio 4.x**
- CSS custom (design tokens)
- WCAG 2.1 compliant UI
- Keyboard & focus accessibility

### Backend
- **Python 3.10+**
- **LangChain**
- **ChromaDB**
- **PyPDF**
- **Ollama** (default) / **OpenAI** (optional)

### Modelli supportati
- `qwen3:1.7b` (LLM, locale)
- `nomic-embed-text` (embedding)
- `gpt-4o-mini` (opzionale via OpenAI)

---

## ğŸ“‚ Struttura del progetto

â”œâ”€â”€ app.py # UI + event handling
â”œâ”€â”€ backend.py # RAG backend logic
â”œâ”€â”€ config.py # Configurazioni centralizzate
â”œâ”€â”€ theme.py # Tema UI (WCAG + product-grade)
â”œâ”€â”€ requirements.txt # Dipendenze
â””â”€â”€ README.md

---

## âš™ï¸ Configurazione

### 1ï¸âƒ£ Clona il repository

```bash
git clone https://github.com/tuo-username/rag-chatbot.git
cd rag-chatbot

2ï¸âƒ£ Crea un virtual environment

python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

3ï¸âƒ£ Installa le dipendenze

pip install -r requirements.txt

4ï¸âƒ£ Avvia Ollama (se usi backend locale)

ollama run qwen3:1.7b

5ï¸âƒ£ Avvia lâ€™app

python app.py
Apri ğŸ‘‰ http://localhost:7860

ğŸ”„ Backend: Ollama vs OpenAI

Nel file config.py puoi scegliere il backend:

BACKEND_TYPE = "ollama"   # oppure "openai"
```

Per OpenAI:

export OPENAI_API_KEY="your_api_key"

ğŸ¨ UI & AccessibilitÃ 

ğŸ¯ WCAG 2.1 AAA-oriented

Contrast-safe colors

Focus ring visibile

Dark mode senza â€œflipâ€ di colori

Chat bubble proporzionate (product-grade)

Lâ€™interfaccia Ã¨ ispirata a prodotti SaaS moderni (ChatGPT-like)
senza copiare brand o CSS proprietari

ğŸš€ Performance & ScalabilitÃ 

Chunking configurabile

Caching per documento

Limite massimo chunk per PDF

Retriever k configurabile

Architettura pronta per:

streaming avanzato

memoria conversazionale

multi-document RAG

ğŸ” Sicurezza & Privacy

Nessun dato persistente lato server

Vector store in memoria

Nessun upload remoto obbligatorio

OpenAI usato solo se esplicitamente configurato

ğŸ§ª Stato del progetto

âœ… Stable
ğŸ§© Estendibile


ğŸ‘¤ Autore

Alessandro Benin
Aspiring AI Specialist / Backend Developer


ğŸ“œ Licenza MIT
